{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bdc118-2c45-47de-abd0-dbe42006db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m704.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:13\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/pc/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/pc/.local/lib/python3.10/site-packages (from tensorflow) (67.7.2)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.9/71.9 KB\u001b[0m \u001b[31m811.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/pc/.local/lib/python3.10/site-packages (from tensorflow) (1.26.1)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.8/82.8 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/pc/.local/lib/python3.10/site-packages (from tensorflow) (4.23.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras>=3.5.0\n",
      "  Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard~=2.19.0\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/pc/.local/lib/python3.10/site-packages (from tensorflow) (4.13.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.73.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0\n",
      "  Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/pc/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting namex\n",
      "  Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m405.8/405.8 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich in /home/pc/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (12.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pc/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pc/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pc/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /home/pc/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/pc/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/pc/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (0.9.1)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.1 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 markdown-3.8.2 ml-dtypes-0.5.1 namex-0.1.0 opt-einsum-3.4.0 optree-0.16.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891d20e1-19a9-4b28-8b35-fba747e0f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efffdd2-68fc-4d24-b802-fd058b24b035",
   "metadata": {},
   "source": [
    "# MALO BOLJI REZ, PRECIZNOST PO KLASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3f0f8-e8e9-4b63-982b-088e6a2d5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "folder = \"../proba2/direct\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Build simple NN\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_np.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # multi-class\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_np, y_train_cat, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f379705-1d73-4aff-ab16-c666e532f2f3",
   "metadata": {},
   "source": [
    "# JOS BOLJI, OVERSAMPLING URADJEN PLUS PRECIZNOST PO KLASI KAO METRIKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51098d6e-a3f8-4c04-bb41-e8b71da5569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "folder = \"../proba2/direct\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors = 2)\n",
    "X_train_smote, y_train_enc_smote = smote.fit_resample(X_train_np, y_train_enc)\n",
    "\n",
    "# 2ï¸âƒ£ One-hot encode again (SMOTE returns encoded labels, not one-hot)\n",
    "y_train_cat_smote = to_categorical(y_train_enc_smote)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_smote.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat_smote.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "# ğŸ‘‡ Train with SMOTE-resampled data!\n",
    "model.fit(X_train_smote, y_train_cat_smote, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef8778-f11f-4f06-a190-1602231a568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rezultati prethodnog:\n",
    "\"\"\"\n",
    "Classification report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "   HCoV-229E       1.00      1.00      1.00       153\n",
    "   HCoV-HKU1       0.89      1.00      0.94        99\n",
    "   HCoV-NL63       1.00      0.99      1.00       214\n",
    "   HCoV-OC43       0.99      0.99      0.99       366\n",
    "         IBV       1.00      1.00      1.00      3153\n",
    "    MERS-CoV       1.00      1.00      1.00       395\n",
    "    SARS-CoV       1.00      1.00      1.00         3\n",
    "   SARS-CoV2       1.00      1.00      1.00      2133\n",
    "     bat-CoV       0.89      1.00      0.94        16\n",
    "  bovine-CoV       0.99      0.99      0.99       378\n",
    "  canine-CoV       0.96      0.98      0.97       219\n",
    " dolphin-CoV       1.00      1.00      1.00         3\n",
    "  equine-CoV       1.00      1.00      1.00         7\n",
    "  feline-CoV       0.99      0.99      0.99       536\n",
    "  ferret-CoV       1.00      1.00      1.00        13\n",
    "hedgehog-CoV       1.00      1.00      1.00         6\n",
    " porcine-CoV       1.00      1.00      1.00       132\n",
    "  rabbit-CoV       0.86      1.00      0.92         6\n",
    "     rat-CoV       0.89      1.00      0.94         8\n",
    "  turkey-CoV       1.00      1.00      1.00        27\n",
    "\n",
    "    accuracy                           1.00      7867\n",
    "   macro avg       0.97      1.00      0.98      7867\n",
    "weighted avg       1.00      1.00      1.00      7867\n",
    "\n",
    "Accuracy:  0.9956781492309648\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e73e5-b216-4008-ac77-e7a7c20e6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "folder = \"../proba2/indirect\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors = 2)\n",
    "X_train_smote, y_train_enc_smote = smote.fit_resample(X_train_np, y_train_enc)\n",
    "\n",
    "# 2ï¸âƒ£ One-hot encode again (SMOTE returns encoded labels, not one-hot)\n",
    "y_train_cat_smote = to_categorical(y_train_enc_smote)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_smote.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat_smote.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "# ğŸ‘‡ Train with SMOTE-resampled data!\n",
    "model.fit(X_train_smote, y_train_cat_smote, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fc95a-35c1-4cf4-8280-ba7df0df7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REZ ZA INDIREKTNE:\n",
    "\"\"\"\n",
    "Classification report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "   HCoV-229E       0.99      1.00      1.00       153\n",
    "   HCoV-HKU1       0.98      1.00      0.99        99\n",
    "   HCoV-NL63       1.00      1.00      1.00       214\n",
    "   HCoV-OC43       0.99      0.98      0.99       366\n",
    "         IBV       1.00      1.00      1.00      3153\n",
    "    MERS-CoV       1.00      0.99      0.99       395\n",
    "    SARS-CoV       1.00      1.00      1.00         3\n",
    "   SARS-CoV2       1.00      1.00      1.00      2133\n",
    "     bat-CoV       1.00      0.94      0.97        16\n",
    "  bovine-CoV       0.99      1.00      0.99       378\n",
    "  canine-CoV       0.98      0.96      0.97       219\n",
    " dolphin-CoV       1.00      1.00      1.00         3\n",
    "  equine-CoV       0.14      1.00      0.25         7\n",
    "  feline-CoV       0.99      0.93      0.96       536\n",
    "  ferret-CoV       1.00      0.92      0.96        13\n",
    "hedgehog-CoV       1.00      1.00      1.00         6\n",
    " porcine-CoV       1.00      1.00      1.00       132\n",
    "  rabbit-CoV       0.86      1.00      0.92         6\n",
    "     rat-CoV       0.89      1.00      0.94         8\n",
    "  turkey-CoV       0.96      0.96      0.96        27\n",
    "\n",
    "    accuracy                           0.99      7867\n",
    "   macro avg       0.94      0.98      0.94      7867\n",
    "weighted avg       1.00      0.99      0.99      7867\n",
    "\n",
    "Accuracy:  0.9912291852040168\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9382e278-a1df-4554-80c4-c3c8f0a66cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique repeats: 798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-07-01 08:57:07.139265: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 08:57:07.398446: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22503600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8205 - loss: 0.8493 - val_accuracy: 0.9974 - val_loss: 0.0472\n",
      "Epoch 2/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9754 - loss: 0.1205 - val_accuracy: 0.9974 - val_loss: 0.0339\n",
      "Epoch 3/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9858 - loss: 0.0743 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
      "Epoch 4/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0503 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 5/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9914 - loss: 0.0373 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0321 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 7/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9906 - loss: 0.0349 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 8/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0259 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 9/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9912 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 10/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0268 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 11/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9937 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 12/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9948 - loss: 0.0179 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 13/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9929 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 14/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9949 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 15/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9942 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 16/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9941 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 17/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9937 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 18/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9952 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 19/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 20/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9937 - loss: 0.0170 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    MERS-CoV       1.00      0.99      1.00       395\n",
      "    SARS-CoV       1.00      1.00      1.00         3\n",
      "     bat-CoV       1.00      1.00      1.00        16\n",
      "  bovine-CoV       1.00      1.00      1.00       378\n",
      "  canine-CoV       0.96      0.99      0.97       219\n",
      "  feline-CoV       1.00      0.99      0.99       536\n",
      "hedgehog-CoV       1.00      1.00      1.00         6\n",
      " porcine-CoV       1.00      1.00      1.00       132\n",
      "\n",
      "    accuracy                           0.99      1685\n",
      "   macro avg       0.99      1.00      1.00      1685\n",
      "weighted avg       0.99      0.99      0.99      1685\n",
      "\n",
      "Accuracy:  0.9928783382789318\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "folder = \"../proba2/direct\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Build simple NN\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_np.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # multi-class\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_np, y_train_cat, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e301d27-f911-4118-a4c1-9516485ff8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique repeats: 1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-07-01 08:58:57.309534: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 28397400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8485 - loss: 0.9734 - val_accuracy: 0.9974 - val_loss: 0.1068\n",
      "Epoch 2/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9800 - loss: 0.1389 - val_accuracy: 1.0000 - val_loss: 0.0142\n",
      "Epoch 3/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9869 - loss: 0.0583 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
      "Epoch 4/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9892 - loss: 0.0554 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 5/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9838 - loss: 0.0576 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 6/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9908 - loss: 0.0398 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 7/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9885 - loss: 0.0380 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 8/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9908 - loss: 0.0384 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9914 - loss: 0.0308 - val_accuracy: 1.0000 - val_loss: 8.3455e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0298 - val_accuracy: 1.0000 - val_loss: 6.7997e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9915 - loss: 0.0315 - val_accuracy: 1.0000 - val_loss: 5.6169e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9923 - loss: 0.0329 - val_accuracy: 1.0000 - val_loss: 4.9718e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0307 - val_accuracy: 1.0000 - val_loss: 4.7041e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9915 - loss: 0.0293 - val_accuracy: 1.0000 - val_loss: 4.3944e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9928 - loss: 0.0302 - val_accuracy: 1.0000 - val_loss: 3.6217e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9957 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 4.1283e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9936 - loss: 0.0268 - val_accuracy: 1.0000 - val_loss: 3.3641e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9922 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 2.8271e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9953 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 2.7155e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9952 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 2.8332e-04\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    MERS-CoV       1.00      0.99      1.00       395\n",
      "    SARS-CoV       1.00      1.00      1.00         3\n",
      "     bat-CoV       0.94      1.00      0.97        16\n",
      "  bovine-CoV       1.00      1.00      1.00       378\n",
      "  canine-CoV       0.99      0.97      0.98       219\n",
      "  feline-CoV       0.98      1.00      0.99       536\n",
      "hedgehog-CoV       1.00      1.00      1.00         6\n",
      " porcine-CoV       1.00      1.00      1.00       132\n",
      "\n",
      "    accuracy                           0.99      1685\n",
      "   macro avg       0.99      0.99      0.99      1685\n",
      "weighted avg       0.99      0.99      0.99      1685\n",
      "\n",
      "Accuracy:  0.9922848664688427\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "folder = \"../proba2/indirect\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSet\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSet/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Build simple NN\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_np.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # multi-class\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_np, y_train_cat, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2701709d-94e1-4559-b983-724c60388f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique repeats: 4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 09:04:07.604543: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 121796160 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8735 - loss: 0.8358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 09:04:13.705706: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 13559880 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.8749 - loss: 0.8285 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
      "Epoch 2/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9906 - loss: 0.0526 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 3/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9960 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 4/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9969 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 5/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9985 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 6/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9984 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 7/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 8/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 9/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.9987 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 10/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9949 - val_loss: 0.0042\n",
      "Epoch 11/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9949 - val_loss: 0.0062\n",
      "Epoch 12/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9949 - val_loss: 0.0056\n",
      "Epoch 13/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9949 - val_loss: 0.0039\n",
      "Epoch 14/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 6.7734e-04 - val_accuracy: 0.9949 - val_loss: 0.0078\n",
      "Epoch 15/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 5.6942e-04 - val_accuracy: 0.9949 - val_loss: 0.0062\n",
      "Epoch 16/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 4.1635e-04 - val_accuracy: 0.9949 - val_loss: 0.0064\n",
      "Epoch 17/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.8110e-04 - val_accuracy: 0.9949 - val_loss: 0.0059\n",
      "Epoch 18/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.6492e-04 - val_accuracy: 0.9949 - val_loss: 0.0079\n",
      "Epoch 19/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.4116e-04 - val_accuracy: 0.9949 - val_loss: 0.0075\n",
      "Epoch 20/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8186e-04 - val_accuracy: 0.9949 - val_loss: 0.0078\n",
      "\u001b[1m10/53\u001b[0m \u001b[32mâ”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 09:05:31.212537: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 58262400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    MERS-CoV       1.00      1.00      1.00       395\n",
      "    SARS-CoV       1.00      1.00      1.00         3\n",
      "     bat-CoV       1.00      0.93      0.97        15\n",
      "  bovine-CoV       1.00      1.00      1.00       375\n",
      "  canine-CoV       0.98      0.99      0.98       218\n",
      "  feline-CoV       0.99      0.99      0.99       536\n",
      "hedgehog-CoV       1.00      1.00      1.00         6\n",
      " porcine-CoV       1.00      1.00      1.00       132\n",
      "\n",
      "    accuracy                           0.99      1680\n",
      "   macro avg       1.00      0.99      0.99      1680\n",
      "weighted avg       0.99      0.99      0.99      1680\n",
      "\n",
      "Accuracy:  0.9946428571428572\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "folder = \"../proba3/DC/\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSetNucl\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSetNucl/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSetNucl\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSetNucl/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Build simple NN\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_np.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # multi-class\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_np, y_train_cat, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b7c43a-88a2-4fc7-8570-5c3f4f97675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique repeats: 4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.8953 - loss: 0.7545 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 2/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9896 - loss: 0.1138 - val_accuracy: 0.9974 - val_loss: 0.0381\n",
      "Epoch 3/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9929 - loss: 0.1119 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
      "Epoch 4/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9956 - loss: 0.0231 - val_accuracy: 0.9949 - val_loss: 0.0060\n",
      "Epoch 5/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0265 - val_accuracy: 0.9974 - val_loss: 0.0201\n",
      "Epoch 6/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0074 - val_accuracy: 0.9974 - val_loss: 0.0087\n",
      "Epoch 7/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.9974 - val_loss: 0.0059\n",
      "Epoch 8/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9974 - val_loss: 0.0062\n",
      "Epoch 9/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9972 - loss: 0.0151 - val_accuracy: 0.9974 - val_loss: 0.0051\n",
      "Epoch 10/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9974 - val_loss: 0.0082\n",
      "Epoch 11/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9974 - val_loss: 0.0091\n",
      "Epoch 12/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9974 - val_loss: 0.0055\n",
      "Epoch 13/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.9939e-04 - val_accuracy: 0.9974 - val_loss: 0.0067\n",
      "Epoch 14/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.7514e-04 - val_accuracy: 0.9974 - val_loss: 0.0081\n",
      "Epoch 15/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.8435e-04 - val_accuracy: 0.9974 - val_loss: 0.0087\n",
      "Epoch 16/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.8922e-04 - val_accuracy: 0.9974 - val_loss: 0.0097\n",
      "Epoch 17/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.7559e-04 - val_accuracy: 0.9923 - val_loss: 0.0076\n",
      "Epoch 18/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.7568e-04 - val_accuracy: 0.9974 - val_loss: 0.0076\n",
      "Epoch 19/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.4751e-04 - val_accuracy: 0.9923 - val_loss: 0.0086\n",
      "Epoch 20/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.2600e-04 - val_accuracy: 0.9923 - val_loss: 0.0093\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    MERS-CoV       1.00      1.00      1.00       395\n",
      "    SARS-CoV       1.00      1.00      1.00         3\n",
      "     bat-CoV       1.00      0.93      0.97        15\n",
      "  bovine-CoV       1.00      1.00      1.00       375\n",
      "  canine-CoV       0.99      0.99      0.99       218\n",
      "  feline-CoV       0.99      0.99      0.99       536\n",
      "hedgehog-CoV       1.00      1.00      1.00         6\n",
      " porcine-CoV       1.00      1.00      1.00       132\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      0.99      0.99      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "Accuracy:  0.9958333333333333\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "folder = \"../proba3/DC/\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSetNucl\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSetNucl/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSetNucl\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSetNucl/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Build simple NN\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_np.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # multi-class\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_np, y_train_cat, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fc2e84-ab6e-474e-91e5-52b797191913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique repeats: 5163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.8908 - loss: 0.6853 - val_accuracy: 0.9949 - val_loss: 0.5406\n",
      "Epoch 2/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9863 - loss: 0.3491 - val_accuracy: 0.9949 - val_loss: 0.0752\n",
      "Epoch 3/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9964 - loss: 0.0260 - val_accuracy: 0.9949 - val_loss: 0.3650\n",
      "Epoch 4/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9950 - loss: 0.1313 - val_accuracy: 1.0000 - val_loss: 8.6486e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9992 - loss: 0.0067 - val_accuracy: 0.9974 - val_loss: 0.0117\n",
      "Epoch 6/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9979 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 4.0339e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 4.5531e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 4.7580e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 9.6031e-04 - val_accuracy: 1.0000 - val_loss: 4.6530e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 5.2252e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 6.0771e-04 - val_accuracy: 1.0000 - val_loss: 5.0526e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.4810e-04 - val_accuracy: 1.0000 - val_loss: 6.0629e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.5649e-04 - val_accuracy: 1.0000 - val_loss: 5.7229e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.1322e-04 - val_accuracy: 1.0000 - val_loss: 6.0100e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.7099e-04 - val_accuracy: 1.0000 - val_loss: 6.1293e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.9153e-04 - val_accuracy: 1.0000 - val_loss: 6.1115e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6006e-04 - val_accuracy: 1.0000 - val_loss: 6.5333e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6047e-04 - val_accuracy: 1.0000 - val_loss: 6.3491e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.4989e-04 - val_accuracy: 1.0000 - val_loss: 6.6578e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.5985e-04 - val_accuracy: 1.0000 - val_loss: 6.7929e-04\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    MERS-CoV       1.00      1.00      1.00       395\n",
      "    SARS-CoV       1.00      1.00      1.00         3\n",
      "     bat-CoV       1.00      0.93      0.97        15\n",
      "  bovine-CoV       1.00      1.00      1.00       375\n",
      "  canine-CoV       0.99      0.98      0.98       218\n",
      "  feline-CoV       0.99      0.99      0.99       536\n",
      "hedgehog-CoV       1.00      1.00      1.00         6\n",
      " porcine-CoV       1.00      1.00      1.00       132\n",
      "\n",
      "    accuracy                           0.99      1680\n",
      "   macro avg       1.00      0.99      0.99      1680\n",
      "weighted avg       0.99      0.99      0.99      1680\n",
      "\n",
      "Accuracy:  0.9940476190476191\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "folder = \"../proba3/IC/\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSetNucl\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSetNucl/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSetNucl\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSetNucl/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Build simple NN\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_np.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # multi-class\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_np, y_train_cat, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32299432-141e-4b84-8d39-f4acbd992e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique repeats: 4897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9205 - loss: 0.6652 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 2/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9908 - loss: 0.1376 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 3/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9964 - loss: 0.0174 - val_accuracy: 0.9974 - val_loss: 0.0087\n",
      "Epoch 4/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9980 - loss: 0.0147 - val_accuracy: 0.9974 - val_loss: 0.0133\n",
      "Epoch 5/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9978 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 2.8414e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9991 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 2.3215e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 2.5754e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 2.4391e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.1679e-04 - val_accuracy: 1.0000 - val_loss: 2.5207e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 2.3920e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 2.1857e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 7.0281e-04 - val_accuracy: 1.0000 - val_loss: 2.1622e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.9550e-04 - val_accuracy: 1.0000 - val_loss: 2.1847e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 2.7932e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9999 - loss: 7.8661e-04 - val_accuracy: 1.0000 - val_loss: 3.0435e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 2.0224e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0016 - val_accuracy: 0.9974 - val_loss: 0.0036\n",
      "Epoch 18/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9984 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 6.3573e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9995 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 20/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.7427e-04 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    MERS-CoV       1.00      0.99      1.00       395\n",
      "    SARS-CoV       1.00      1.00      1.00         3\n",
      "     bat-CoV       1.00      0.93      0.97        15\n",
      "  bovine-CoV       1.00      1.00      1.00       375\n",
      "  canine-CoV       0.99      0.99      0.99       218\n",
      "  feline-CoV       0.99      0.99      0.99       536\n",
      "hedgehog-CoV       0.86      1.00      0.92         6\n",
      " porcine-CoV       1.00      1.00      1.00       132\n",
      "\n",
      "    accuracy                           0.99      1680\n",
      "   macro avg       0.98      0.99      0.98      1680\n",
      "weighted avg       0.99      0.99      0.99      1680\n",
      "\n",
      "Accuracy:  0.9946428571428572\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "folder = \"../proba3/IN/\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labels = []\n",
    "repeats = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                repeat = parts[1]\n",
    "                labels.append(label)\n",
    "                repeats.append(repeat)\n",
    "\n",
    "files = []\n",
    "folder = \"../trainSetNucl\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "labelTrain = []\n",
    "sequencesTrain = []\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTrain.append(record.seq)\n",
    "        labelTrain.append(file.replace(\"../trainSetNucl/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "labelTest = []\n",
    "sequencesTest = []\n",
    "\n",
    "files = []\n",
    "folder = \"../testSetNucl\"\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.startswith(\".\"):\n",
    "        continue\n",
    "    files.append(folder + \"/\" + file)\n",
    "\n",
    "\n",
    "# Read data from each file\n",
    "for file in files:\n",
    "    records = SeqIO.parse(file, \"fasta\")\n",
    "    for record in records:\n",
    "        sequencesTest.append(record.seq)\n",
    "        labelTest.append(file.replace(\"../testSetNucl/\", \"\").replace(\".fasta\", \"\"))\n",
    "\n",
    "known_repeats = list(set(repeats))\n",
    "print(f\"Number of unique repeats: {len(known_repeats)}\")\n",
    "\n",
    "def extract_repeat_counts(sequence, repeat_list):\n",
    "    return [sequence.count(r) for r in repeat_list]\n",
    "\n",
    "X_train = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTrain]\n",
    "y_train = labelTrain\n",
    "\n",
    "X_test = [extract_repeat_counts(seq, known_repeats) for seq in sequencesTest]\n",
    "y_test = labelTest\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode for NN\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# Make sure input is NumPy\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Build simple NN\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_np.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # multi-class\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_np, y_train_cat, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_np)\n",
    "y_pred_enc = np.argmax(y_pred_probs, axis=1)\n",
    "y_pred = encoder.inverse_transform(y_pred_enc)\n",
    "\n",
    "# Report\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ee87f-8a07-411a-acfa-0d49fad5109c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
